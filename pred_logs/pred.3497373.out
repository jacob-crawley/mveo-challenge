/fastdata/acc19jc/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of "
/fastdata/acc19jc/lib/python3.9/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
check average score 1.0
train 770
check average score 1.0
train_val 76
test 0
### Data loaded #######
Dataloader length == 5
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:20<01:21, 20.42s/it] 40%|████      | 2/5 [00:21<00:26,  8.94s/it] 60%|██████    | 3/5 [00:22<00:10,  5.27s/it] 80%|████████  | 4/5 [00:23<00:03,  3.55s/it]100%|██████████| 5/5 [00:23<00:00,  2.56s/it]100%|██████████| 5/5 [00:24<00:00,  4.82s/it]
PREDS:

torch.Size([1048576]) torch.Size([1048576])
PREDS:

torch.Size([1048576]) torch.Size([1048576])
PREDS:

torch.Size([1048576]) torch.Size([1048576])
PREDS:

torch.Size([1048576]) torch.Size([1048576])
PREDS:

torch.Size([786432]) torch.Size([786432])
Average Jaccard Per Class = tensor([0.0000, 0.0589, 0.0264, 0.0000, 0.0029, 0.0098, 0.0000, 0.0005, 0.0000,
        0.0446, 0.0323, 0.0378, 0.0000, 0.0025, 0.0000, 0.0000],
       device='cuda:0')
tensor([0.0589, 0.0264, 0.0000, 0.0029, 0.0098, 0.0000, 0.0005, 0.0323, 0.0378,
        0.0000, 0.0025, 0.0000], device='cuda:0')
Overall Average = 0.014267802238464355
Standard Deviation (Jaccard) = 0.019793136045336723
Mean Accuracy = 0.0, Accuracy Standard Dev. = 0.0
[[     0      0      0      0      0      0      0     19  12511  16554
   28230  57164  48802  42760  55855  56760]
 [ 85575  30765  20247  17391  10405   7224    510    468   5336   5732
    9993  20835  14625  12484  18131  16367]
 [ 28496   7782   5985   5332   4650   3135    140     33      0      0
       0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0    481    928
    2159   6585   5784   6790   5607   7359]
 [  9831   5896   3616   1823    868    639      0    652   4494  16846
   25857  35266  34899  29641  44632  51459]
 [ 64477  12670  16144  14397   9549   1873    238    268      0      0
       0      0      0      0      0      0]
 [     0      0      0      0      0      0      0   2229  33944  61466
   86234 158859 147357 108343 151897 163740]
 [234717  59569  54669  50360  43608  18969    283    286      0      0
       0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0  19436  40977
   54643 106563 100953  59367 107191  89623]
 [126822  32378  37412  40024  27198   9524    610   1027  10043  17601
   22604  32432  28584  24608  38295  31384]
 [ 48933   9372  12113  15007  10364   3567    529   1584  12521   9505
   19527  36954  27908  20490  32652  27478]
 [ 44142   7660  14036  14248   7880   4780    134    175      0      0
       0      0      0      0      0      0]
 [     0      0      0      0      0      0      0     28    177    283
     318   1374   1537    746   1225   1064]
 [  1704    721    971    601    101     86     45     76      0      0
       0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0]]
